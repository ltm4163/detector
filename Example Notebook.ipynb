{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft2, fftshift\n",
    "from scipy.signal import correlate2d\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noise_residual(image, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Extract noise residuals from an image using Gaussian denoising.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image as a 2D NumPy array (grayscale) or 3D NumPy array (color).\n",
    "    - sigma: Standard deviation for the Gaussian filter.\n",
    "\n",
    "    Returns:\n",
    "    - residual: Noise residuals as a 2D NumPy array (grayscale) or 3D NumPy array (color).\n",
    "    \"\"\"\n",
    " \n",
    "    residual = np.zeros_like(image)\n",
    "    for channel in range(3):\n",
    "        denoised_channel = gaussian_filter(image[:, :, channel], sigma=sigma)\n",
    "        residual[:, :, channel] = image[:, :, channel] - denoised_channel\n",
    "\n",
    "    # Normalize the residual for visualization\n",
    "    residual = residual - np.min(residual)\n",
    "    residual = residual / np.max(residual)\n",
    "\n",
    "    return residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image in grayscale or color\n",
    "image = cv2.imread('generated_image.png', cv2.IMREAD_COLOR)  # For grayscale\n",
    "# For color image: image = cv2.imread('sample_image.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Normalize the image to [0, 1] range\n",
    "image = image / 255.0\n",
    "\n",
    "# Extract noise residuals\n",
    "residual = extract_noise_residual(image, sigma=1.0)\n",
    "\n",
    "# Plot the original image and its noise residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Noise Residuals')\n",
    "plt.imshow(residual)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_power_spectrum(residual):\n",
    "    \"\"\"\n",
    "    Compute the power spectrum of the noise residual.\n",
    "\n",
    "    Parameters:\n",
    "    - residual: Noise residual as a 3D NumPy array (H x W x 3).\n",
    "\n",
    "    Returns:\n",
    "    - power_spectrum: The average power spectrum across all color channels.\n",
    "    \"\"\"\n",
    "    power_spectra = []\n",
    "    for channel in range(3):\n",
    "        # Compute the 2D Fourier Transform and shift the zero-frequency component to the center\n",
    "        f_transform = fft2(residual[:, :, channel])\n",
    "        f_shifted = fftshift(f_transform)\n",
    "\n",
    "        # Calculate the power spectrum\n",
    "        power_spectrum = np.abs(f_shifted) ** 2\n",
    "        power_spectra.append(power_spectrum)\n",
    "    \n",
    "    # Average the power spectra across all channels\n",
    "    average_power_spectrum = np.mean(power_spectra, axis=0)\n",
    "    return average_power_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_spectrum = compute_power_spectrum(residual)\n",
    "\n",
    "# Plot the power spectrum\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.title(\"Power Spectrum of Noise Residuals\")\n",
    "plt.imshow(np.log1p(power_spectrum), cmap='viridis')  # Logarithmic scale for better visualization\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_autocorrelation(residual):\n",
    "    \"\"\"\n",
    "    Compute the autocorrelation of the noise residual.\n",
    "\n",
    "    Parameters:\n",
    "    - residual: Noise residual as a 3D NumPy array (H x W x 3).\n",
    "\n",
    "    Returns:\n",
    "    - autocorrelation: The average autocorrelation function across all color channels.\n",
    "    \"\"\"\n",
    "    print(\"calculating autocorrelation...\")\n",
    "    autocorrelations = []\n",
    "    for channel in range(3):\n",
    "        # Calculate 2D autocorrelation using correlate2d\n",
    "        autocorr = correlate2d(residual[:, :, channel], residual[:, :, channel], mode='same')\n",
    "        autocorrelations.append(autocorr)\n",
    "    \n",
    "    # Average the autocorrelations across all channels\n",
    "    average_autocorrelation = np.mean(autocorrelations, axis=0)\n",
    "    \n",
    "    # Normalize the autocorrelation for visualization\n",
    "    average_autocorrelation -= np.min(average_autocorrelation)\n",
    "    average_autocorrelation /= np.max(average_autocorrelation)\n",
    "    \n",
    "    return average_autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the autocorrelation of the residuals\n",
    "autocorrelation = compute_autocorrelation(residual)\n",
    "\n",
    "# Plot the autocorrelation\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.title(\"Autocorrelation of Noise Residuals\")\n",
    "plt.imshow(autocorrelation)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_sample_image(image, stride=2):\n",
    "    \"\"\"\n",
    "    Perform sparse sampling of an image by taking every nth pixel based on the stride.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 3D NumPy array (H x W x 3).\n",
    "    - stride: Step size for sampling (default is 2).\n",
    "\n",
    "    Returns:\n",
    "    - sampled_image: The sparsely sampled image.\n",
    "    \"\"\"\n",
    "    sampled_image = image[::stride, ::stride, :]\n",
    "    return sampled_image\n",
    "\n",
    "\n",
    "start_time_sparse = time.time()\n",
    "stride = 4\n",
    "sparse_residual_image = sparse_sample_image(residual, stride=stride)\n",
    "autocorr_sparse = compute_autocorrelation(sparse_residual_image)\n",
    "time_sparse = time.time() - start_time_sparse\n",
    "\n",
    "print(\"time sparse: \", time_sparse)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Unsampled')\n",
    "plt.imshow(autocorrelation)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Sparse')\n",
    "plt.imshow(autocorr_sparse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import process_dataset\n",
    "\n",
    "\n",
    "print(\"here\")\n",
    "features, labels = process_dataset('data/ffhq/images1024x1024', '/Users/lincolnmercuro/Desktop/Deepfake Research/detector/data/diffusion')\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest classifier\n",
    "from sklearn.base import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
